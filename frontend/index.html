<!DOCTYPE html>
<html lang="de">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>Frag Friedrich Barbarossa</title>

<link rel="icon" href="avatar.png" type="image/png">
<link rel="apple-touch-icon" href="avatar.png">
<meta name="theme-color" content="#000000">

<style>
  body {
    margin: 0;
    overflow: hidden;
    background: black;
    display: flex;
    justify-content: center;
    align-items: center;
    height: 100vh;
    font-family: "Georgia", serif;
    color: white;
  }
  h1 {
    position: absolute;
    top: 20px;
    width: 100%;
    text-align: center;
    font-size: 2em;
    color: #e0b36b;
    animation: pulse 3s ease-in-out infinite;
  }
  @keyframes pulse {
    0%,100% { opacity: 1; }
    50% { opacity: 0.85; }
  }
  #avatarCanvas { width:100%; height:100%; display:block; }
  #micBtn {
    position:absolute;
    bottom:60px;
    left:50%;
    transform:translateX(-50%);
    width:80px;
    height:80px;
    border-radius:50%;
    border:none;
    background:#222;
    color:white;
    font-size:32px;
    cursor:pointer;
  }
  #micBtn:hover { background:#444; }
  #loading {
    position:absolute;
    top:50%;
    left:50%;
    transform:translate(-50%,-50%);
    color:#ccc;
    font-size:1.1em;
    text-align:center;
  }
  footer {
  position: absolute;
  bottom: 20px;
  width: 100%;
  text-align: center;
  color: #888; /* grau wie frÃ¼her */
  font-size: 0.9em;
}

footer a {
  color: #888; /* Link ebenfalls grau */
  text-decoration: none;
}

footer a:hover {
  color: #bbb; /* leicht heller beim Hover */
}
</style>
</head>

<body>
<h1>Frag Friedrich</h1>
<div id="loading">Avatar wird geladenâ€¦</div>
<canvas id="avatarCanvas"></canvas>
<button id="micBtn">ðŸŽ¤</button>
<footer>
Â© 2025 <a href="https://christoph-dammann.de" target="_blank">Dr. Christoph Dammann</a>
</footer>

<script src="https://cdn.jsdelivr.net/npm/three@0.146.0/build/three.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/three@0.146.0/examples/js/loaders/GLTFLoader.js"></script>

<script>

/* ===============================
   STATE-VARIABLEN + SICHERHEIT
================================ */

// === Blendshape-Indices (Default bis Modell geladen) ===
let jawOpenIndex = null;
let mouthWideIndex = null;
let mouthPuckerIndex = null;
let mouthSmileIndex = null;  // ðŸ†• NEU: mouthSmile fÃ¼r â€žAâ€œ
let mouthFrownIndex = null;  // ðŸ†• NEU: mouthFrown fÃ¼r â€žOâ€œ, â€žMâ€œ, â€žPâ€œ

// Audio / Analyse
let audioCtx, analyser, src;

// HauptzustÃ¤nde
let model, STATE = "idle";
let lastTranscript = "";
let talking = false, greeted = false;
let mouthCooldown = false;          // ðŸ†• Anti-Zittern nach Sprachende
let justFinishedSpeaking = false;   // mikro-Delay nach Speech-Ende

let lipsyncTimer = null;   // Timer fÃ¼r Text-Lipsync wÃ¤hrend TTS

// â­ NEU: verhindert recognition.start() Doppelklick-Fehler
let recognizing = false;            // WICHTIG: global, nicht in resetMovements!

// === BewegungszustÃ¤nde ===
let frontalFix = true;              // nach Laden: noch nicht frontal
let hmNeigen   = false, hmStartTime = 0;
let rising     = false, riseStartTime = 0;

// â­ RÃ¼ckkehr nach rechts â€“ nur am ENDE gesteuert!
let toIdlePose   = false, toIdleStart = 0;
const toIdleDuration = 3000;        // sanfte RÃ¼ckkehr (kann z.B. 3000 sein)

// === Animationszeiten (ms) ===
const hmDuration   = 8000;          // Hmmm sehr langsam
const riseDuration = 3000;          // BegrÃ¼ÃŸung / Antwort â†’ frontal

// === Grundposition Avatar ===
let baseRotY = -0.35;               // leicht nach rechts geneigt
let baseRotX = 0.25;
let baseY = 0;

// ðŸ›¡ï¸ NIEMALS gleichzeitig mehrere Bewegungen
// â— WICHTIG: toIdlePose DARF NICHT zurÃ¼ckgesetzt werden!
//    (wird zentral Ã¼ber die StateMachine gesteuert)
function resetMovements() {
  hmNeigen = false;
  rising   = false;
  // talking NICHT hier setzen!
}
/* --------------------------------------------------
   BLENDSHAPE SETZEN â€“ MUSS GLOBAL GANZ OBEN VERFÃœGBAR SEIN
-------------------------------------------------- */
function setBlendshape(index, value) {
  if (index === null || !model) return;

  model.traverse(obj => {
    if (obj.isMesh && obj.morphTargetInfluences) {
      obj.morphTargetInfluences[index] = value;
    }
  });
}

/* -----------------------------
   THREE.js SETUP
----------------------------- */
const scene = new THREE.Scene();
const camera = new THREE.PerspectiveCamera(
  30,
  window.innerWidth / window.innerHeight,
  0.1,
  1000
);
camera.position.set(0, 0, 2.8);

const renderer = new THREE.WebGLRenderer({
  canvas: document.getElementById("avatarCanvas"),
  antialias: true
});
renderer.setSize(window.innerWidth, window.innerHeight);
renderer.setPixelRatio(window.devicePixelRatio);
renderer.setClearColor(0x000000);

/* LICHT */
const dirLight = new THREE.DirectionalLight(0xffffff, 2);
dirLight.position.set(1, 1, 2);
scene.add(dirLight);

const ambLight = new THREE.AmbientLight(0xffffff, 0.8);
scene.add(ambLight);

const frontLight = new THREE.PointLight(0xffffff, 0.8);
frontLight.position.set(0, 0.5, 2);
scene.add(frontLight);

/* --------------------------------------------------
   MODEL LADEN  (mit Blendshape-Erkennung)
-------------------------------------------------- */
const loader = new THREE.GLTFLoader();
loader.load("./avatar.glb", gltf => {

  model = gltf.scene;

  const box = new THREE.Box3().setFromObject(model);
  const size = box.getSize(new THREE.Vector3());
  model.scale.setScalar((1.5 / Math.max(size.x, size.y, size.z)) * 0.8);

  const center = box.getCenter(new THREE.Vector3());
  model.position.sub(center);

  baseY = model.position.y;
  model.rotation.y = baseRotY - Math.PI / 2;
  model.rotation.x = baseRotX;

  model.traverse(obj => {
    if (obj.isMesh && obj.morphTargetDictionary) {
      console.log("Mesh:", obj.name, obj.morphTargetDictionary);

      for (const [name, idx] of Object.entries(obj.morphTargetDictionary)) {
        const lower = name.toLowerCase();

        if (lower.includes("jaw"))   jawOpenIndex = idx;
        if (lower.includes("wide"))  mouthWideIndex = idx;
        if (lower.includes("puck"))  mouthPuckerIndex = idx;
        if (lower.includes("smile")) mouthSmileIndex = idx;
        if (lower.includes("frown")) mouthFrownIndex = idx;
      }
    }
  });

  console.log("âœ” FINAL Blendshape-Indices:",
              "jawOpen =", jawOpenIndex,
              "| mouthWide =", mouthWideIndex,
              "| mouthPucker =", mouthPuckerIndex,
              "| mouthSmile =", mouthSmileIndex,
              "| mouthFrown =", mouthFrownIndex);

  scene.add(model);
  document.getElementById("loading").style.display = "none";
  animate();
});

/* -----------------------------
   STATE MACHINE â€“ LOGIK (FINAL)
----------------------------- */

let recognition;
if ("webkitSpeechRecognition" in window) {
  recognition = new webkitSpeechRecognition();
  recognition.lang = "de-DE";
  recognition.continuous = false;

  // Ergebnis speichern:
  recognition.onresult = e => {
    lastTranscript = e.results[0][0].transcript;
  };

  // Aufnahme beendet:
  recognition.onend = () => {

    // â­ Recognition freigeben
    recognizing = false;

    if (STATE === "listen" && lastTranscript) {

      // 1ï¸âƒ£ HMMM â€“ Kopf langsam nach links:
      resetMovements();
      STATE = "hmmm";
      hmNeigen = true;
      hmStartTime = performance.now();
      speak("Ã„hm..... einen Moment", true);

      const MIN_HMMM = 4000;
      setTimeout(() => {

        fetch("/ask", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ text: lastTranscript })
        })
        .then(r => r.json())
        .then(data => {

          // 2ï¸âƒ£ Antwort â†’ frontal
          resetMovements();
          STATE = "answer";
          rising = true;
          riseStartTime = performance.now();

          speak(data.answer);

          // 3ï¸âƒ£ Antwortende â†’ RÃ¼ckkehr nach rechts
          const waitUntilDone = setInterval(() => {

            // â­ NEU: prÃ¼fen, ob TTS UND Text-Lipsync fertig
            if (!talking && !tlActive && !rising) {
              clearInterval(waitUntilDone);
              resetMovements();
              greeted = false;
              STATE = "idle";

              toIdlePose = true;
              toIdleStart = performance.now();
            }

          }, 200);

        })
        .catch(() => {
          resetMovements();
          STATE = "idle";
        });

      }, MIN_HMMM);

    } else {
      resetMovements();
      STATE = "idle";
    }
  };
}

// ====================================
// ANIMATE â€“ FINAL & STABLE
// ====================================
function animate() {
  requestAnimationFrame(animate);
  if (!model) return;

  const now = performance.now();
  const frontalY = -Math.PI / 2;               // frontal
  const rightY   = baseRotY - Math.PI / 2;     // Startpose rechts
  const leftY    = frontalY + 0.25;            // Hmmm = leicht links

  // 0ï¸âƒ£ START: Ausgangsposition (leicht rechts)
  if (frontalFix) {
    model.rotation.y = THREE.MathUtils.lerp(model.rotation.y, rightY, 0.08);
    model.rotation.x = THREE.MathUtils.lerp(model.rotation.x, baseRotX, 0.08);
    renderer.render(scene, camera);
    return;
  }

  // â­ï¸ NEU: Sanfte RÃ¼ckkehr nach rechts nach Antwortende
  if (toIdlePose) {
    const t = (now - toIdleStart) / toIdleDuration;

    model.rotation.y = THREE.MathUtils.lerp(model.rotation.y, rightY, 0.03);
    model.rotation.x = THREE.MathUtils.lerp(model.rotation.x, baseRotX, 0.03);

    if (t >= 1) {
      toIdlePose = false;
    }
  }

  // 1ï¸âƒ£ GREET / ANTWORTBEGINN â†’ FRONTAL
  if (rising) {
    const t = (now - riseStartTime) / riseDuration;
    model.rotation.y = THREE.MathUtils.lerp(model.rotation.y, frontalY, 0.06);
    model.rotation.x = THREE.MathUtils.lerp(model.rotation.x, 0, 0.06);
    if (t >= 1) rising = false;
  }

  // 2ï¸âƒ£ HMMM â†’ LANGSAM LINKS
  else if (hmNeigen) {
    const t = Math.min(1, (now - hmStartTime) / hmDuration);
    model.rotation.x = THREE.MathUtils.lerp(model.rotation.x, baseRotX + 0.25, t);
    model.rotation.y = THREE.MathUtils.lerp(model.rotation.y, leftY, t);
  }

  // 3ï¸âƒ£ ANTWORT â†’ FRONTAL
  else if (STATE === "answer") {
    model.position.y = baseY + Math.sin(now * 0.0015) * 0.008;
    model.rotation.y = THREE.MathUtils.lerp(model.rotation.y, frontalY, 0.03);
    model.rotation.x = THREE.MathUtils.lerp(model.rotation.x, 0, 0.03);
  }

  // 4ï¸âƒ£ TALKING â†’ FRONTAL
  else if (talking) {
    model.position.y = baseY + Math.sin(now * 0.0015) * 0.008;
    model.rotation.y = THREE.MathUtils.lerp(model.rotation.y, frontalY, 0.03);
    model.rotation.x = THREE.MathUtils.lerp(model.rotation.x, 0, 0.03);
  }

  // 5ï¸âƒ£ LISTEN/GREET â†’ FRONTAL
  else if (STATE === "listen" || STATE === "greet") {
    model.position.y = baseY + Math.sin(now * 0.0012) * 0.006;
    model.rotation.y = THREE.MathUtils.lerp(model.rotation.y, frontalY, 0.03);
    model.rotation.x = THREE.MathUtils.lerp(model.rotation.x, 0, 0.03);
  }

  // 6ï¸âƒ£ IDLE â†’ ZURÃœCK NACH RECHTS + ATEM
  else if (STATE === "idle" && !talking && !rising) {
    const breathSpeed = 0.0011 + Math.sin(now * 0.00005) * 0.0004;
    const breathAmp   = 0.006  + Math.sin(now * 0.00008) * 0.003;
    model.position.y  = baseY + Math.sin(now * breathSpeed) * breathAmp;

    model.rotation.y = THREE.MathUtils.lerp(model.rotation.y, rightY, 0.03);
    model.rotation.x = THREE.MathUtils.lerp(model.rotation.x, baseRotX, 0.03);
  }

  // â­ Blickbewegungen
  const driftX = Math.sin(now * 0.0012) * 0.05;
  const driftY = Math.sin(now * 0.0010) * 0.04;

  model.rotation.x = THREE.MathUtils.lerp(model.rotation.x, baseRotX + driftX, 0.03);

  if (!hmNeigen && !rising) {
    model.rotation.y = THREE.MathUtils.lerp(model.rotation.y, model.rotation.y + driftY, 0.018);
  }

  // ðŸŸ¡ IDLE-MUND
  if (!talking && !justFinishedSpeaking && !mouthCooldown && !tlActive) {
    const t2 = now * 0.0013;
    const idleJaw = 0.06 + Math.sin(t2 * 0.7) * 0.015;
    const idleWide   = Math.sin(t2 * 0.9)  * 0.015;
    const idlePucker = Math.cos(t2 * 0.55) * 0.01;

    setBlendshape(jawOpenIndex,     idleJaw);
    setBlendshape(mouthWideIndex,   Math.max(0, idleWide));
    setBlendshape(mouthPuckerIndex, Math.max(0, idlePucker));
    setBlendshape(mouthSmileIndex,  0);
    setBlendshape(mouthFrownIndex,  0);
  }

  renderer.render(scene, camera);
}

 /* -----------------------------
   BUTTON â€“ GREET & LISTEN (FIXED)
----------------------------- */
document.getElementById("micBtn").onclick = () => {

  // â— NEU: Wenn TTS lÃ¤uft â†’ Klicks komplett ignorieren
  if (talking || tlActive) {
    console.warn("â›” Aktion wÃ¤hrend Sprache blockiert.");
    return;
  }

  // â— Wenn Recognition gerade lÃ¤uft â†’ NICHT erneut starten
  if (recognizing) {
    console.warn("âš ï¸ Aufnahme lÃ¤uft bereits â€“ erneuter Start verhindert.");
    return;
  }

  // Erste BetÃ¤tigung â†’ BegrÃ¼ÃŸung
  if (!greeted) {
    resetMovements();
    greeted = true;
    STATE = "greet";

    frontalFix = false;
    rising = true;
    riseStartTime = performance.now();

    speak(
      "Seid gegrÃ¼ÃŸt, mein Freund. Ich bin Friedrich Barbarossa, nach fast neunhundert Jahren im Kaiserberg zu Lautern erwacht. Was ist Euer Begehr?",
      false
    );
    return;
  }

  // SpÃ¤tere BetÃ¤tigung â†’ Spracherkennung starten
  if (!recognition) {
    alert("Spracherkennung wird nicht unterstÃ¼tzt.");
    return;
  }

  resetMovements();
  lastTranscript = "";
  STATE = "listen";

  recognizing = true;
  recognition.start();
};

/* -----------------------------
   1) MÃ„NNLICHE STIMME FEST SETZEN  (GLOBAL!)
----------------------------- */
let maleVoice = null;
let voiceReady = false;

// Stimme auswÃ¤hlen, wenn verfÃ¼gbar
function setMaleVoice() {
  const voices = speechSynthesis.getVoices();

  if (!voices.length) {
    // Chrome lÃ¤dt Stimmen verzÃ¶gert â†’ retry
    setTimeout(setMaleVoice, 150);
    return;
  }

  // bevorzugte Stimme
  maleVoice =
      voices.find(v => v.name === "Microsoft Stefan - German (Germany)") ||
      voices.find(v => v.lang === "de-DE") ||
      voices[0];

  console.log("AusgewÃ¤hlte Stimme:", maleVoice);

  voiceReady = true;

  // Chrome TTS-Warmup â†’ verhindert Roboterstimme und zu frÃ¼hes Ende
  warmupTTS();
}

speechSynthesis.onvoiceschanged = setMaleVoice;
setMaleVoice();

// Chrome Warmup â€“ stumm, aber stabilisiert TTS komplett
function warmupTTS() {
  if (!voiceReady) return;

  const u = new SpeechSynthesisUtterance("â€¦");
  u.volume = 0; // stumm
  u.rate = 1;
  u.pitch = 1;
  u.voice = maleVoice;

  speechSynthesis.speak(u);
}

/* ----------------------------------------
   SPEAK â€“ SYNCHRONE TTS + TEXT-LIPSYNC
---------------------------------------- */
function speak(text, slow = false) {
  if (!text) return;

  // Stimme noch nicht bereit â†’ warten
  if (!voiceReady) {
    console.warn("â³ Stimme noch nicht bereit â€“ speak verzÃ¶gert");
    setTimeout(() => speak(text, slow), 120);
    return;
  }

  // Falls alter Lippen-Timer lÃ¤uft â†’ stoppen
  if (lipsyncTimer) {
    clearInterval(lipsyncTimer);
    lipsyncTimer = null;
  }

  // ðŸ”¥ Flags
  talking  = true;
  tlActive = true;

  // Silben vorbereiten
  const units = tlSplitIntoSyllables(text);
  let idx = 0;

  // Geschwindigkeit pro Silbe
  const baseStep = slow ? 220 : 170;

  // === TTS vorbereiten ===
const u = new SpeechSynthesisUtterance(text);
u.lang  = "de-DE";
u.rate  = slow ? 0.8 : 0.92;
u.pitch = 0.8;
u.voice = maleVoice;

// 1ï¸âƒ£ Start â†’ Lipsync starten
u.onstart = () => {
  if (!units.length) return;

  lipsyncTimer = setInterval(() => {

    // aktuellen Index bestimmen
    let currentIndex = idx;

    if (idx >= units.length) {
      currentIndex = units.length - 1;

      // ðŸ”¥ NEU: leichte Variation auf der letzten Silbe,
      // damit der Mund weiter "lebt"
      const wobble = Math.sin(performance.now() * 0.012) * 0.12;
      const lastSyl = units[currentIndex].trim();

      let v = tlDetectSpecialVisemes(lastSyl) || tlLetterViseme(lastSyl[0]);

      // Variation leicht auf Jaw anwenden
      v = { ...v, jaw: v.jaw + wobble };

      tlApplyViseme(v);
      return;
    }

    const sylRaw = units[currentIndex];
    if (!sylRaw) return;

    const syl = sylRaw.trim();
    if (!syl) return;

    const v = tlDetectSpecialVisemes(syl) || tlLetterViseme(syl[0]);
    tlApplyViseme(v);

    idx++;

  }, baseStep);
}; //  ðŸŸ¢ **HIER** endet onstart richtig!


// 2ï¸âƒ£ Ende â†’ Lipsync stoppen & Mund schlieÃŸen
u.onend = () => {
  console.log("ðŸ›‘ TTS END â€“ lipsyncTimer cleared");

  if (lipsyncTimer) {
    clearInterval(lipsyncTimer);
    lipsyncTimer = null;
  }

  tlResetMouthToIdle();
  tlActive = false;
  talking  = false;

  justFinishedSpeaking = true;
  setTimeout(() => justFinishedSpeaking = false, 80);
};

// 3ï¸âƒ£ Start der TTS Ausgabe
speechSynthesis.speak(u);
}
/* -----------------------------
   RESIZE
----------------------------- */
window.addEventListener("resize", () => {
  camera.aspect = window.innerWidth / window.innerHeight;
  camera.updateProjectionMatrix();
  renderer.setSize(window.innerWidth, window.innerHeight);
});
</script>
  <script src="textLipsync.js"></script>
</body>
</html>
