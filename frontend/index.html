<!DOCTYPE html>
<html lang="de">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>Frag Friedrich Barbarossa</title>

<link rel="icon" href="avatar.png" type="image/png">
<link rel="apple-touch-icon" href="avatar.png">
<meta name="theme-color" content="#000000">

<style>
  body {
    margin: 0;
    overflow: hidden;
    background: black;
    display: flex;
    justify-content: center;
    align-items: center;
    height: 100vh;
    font-family: "Georgia", serif;
    color: white;
  }
  h1 {
    position: absolute;
    top: 20px;
    width: 100%;
    text-align: center;
    font-size: 2em;
    color: #e0b36b;
    animation: pulse 3s ease-in-out infinite;
  }
  @keyframes pulse {
    0%,100% { opacity: 1; }
    50% { opacity: 0.85; }
  }
  #avatarCanvas { width:100%; height:100%; display:block; }
  #micBtn {
    position:absolute;
    bottom:60px;
    left:50%;
    transform:translateX(-50%);
    width:80px;
    height:80px;
    border-radius:50%;
    border:none;
    background:#222;
    color:white;
    font-size:32px;
    cursor:pointer;
  }
  #micBtn:hover { background:#444; }
  #loading {
    position:absolute;
    top:50%;
    left:50%;
    transform:translate(-50%,-50%);
    color:#ccc;
    font-size:1.1em;
    text-align:center;
  }
</style>
</head>

<body>
<h1>Frag Friedrich</h1>
<div id="loading">Avatar wird geladen‚Ä¶</div>
<canvas id="avatarCanvas"></canvas>
<button id="micBtn">üé§</button>

<script src="https://cdn.jsdelivr.net/npm/three@0.146.0/build/three.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/three@0.146.0/examples/js/loaders/GLTFLoader.js"></script>

<script>

/* ===============================
   STATE-VARIABLEN + SICHERHEIT
================================ */

// === Blendshape-Indices (Default bis Modell geladen) ===
let jawOpenIndex = null;
let mouthWideIndex = null;
let mouthPuckerIndex = null;
let mouthSmileIndex = null;
let mouthFrownIndex = null;

// Audio / Analyse
let audioCtx, analyser, src;

// === Hauptzust√§nde ===
let model, STATE = "idle";
let lastTranscript = "";
let talking = false, greeted = false;
let mouthCooldown = false;
let justFinishedSpeaking = false;
let recRunning = false;

// === Guards (Museums-H√§rtung) ===
let wakeGuard = false;               // blockt ersten Klick nach Sleep
let wakeStabilizing = false;         // blockt Recognition direkt nach Wake
let recognitionHandled = false;      // verhindert doppeltes recognition.onend
let askInProgress = false;           // garantiert nur EIN /ask pro Durchlauf

// === Bewegungszust√§nde ===
let frontalFix = true;               // nach Laden: noch nicht frontal
let hmNeigen = false, hmStartTime = 0;
let rising = false, riseStartTime = 0;

// ‚≠ê R√ºckkehr nach rechts ‚Äì nur am ENDE gesteuert!
let toIdlePose = false, toIdleStart = 0;
const toIdleDuration = 3000;

// === Animationszeiten (ms) ===
const hmDuration = 8000;             // Hmmm sehr langsam
const riseDuration = 3000;           // Begr√º√üung / Antwort ‚Üí frontal

// === Grundposition Avatar ===
let baseRotY = -0.35;                // leicht nach rechts geneigt
let baseRotX = 0.25;
let baseY = 0;

// üõ°Ô∏è NIEMALS gleichzeitig mehrere Bewegungen
function resetMovements() {
  hmNeigen = false;
  rising = false;
  talking = false;
}

/* -----------------------------
   THREE.js SETUP
----------------------------- */
const scene = new THREE.Scene();
const camera = new THREE.PerspectiveCamera(
  30,
  window.innerWidth / window.innerHeight,
  0.1,
  1000
);
camera.position.set(0, 0, 2.8);

const renderer = new THREE.WebGLRenderer({
  canvas: document.getElementById("avatarCanvas"),
  antialias: true
});
renderer.setSize(window.innerWidth, window.innerHeight);
renderer.setPixelRatio(window.devicePixelRatio);
renderer.setClearColor(0x000000);

/* LICHT ‚Äì KORREKT */
const dirLight = new THREE.DirectionalLight(0xffffff, 2);
dirLight.position.set(1, 1, 2);
scene.add(dirLight);

const ambLight = new THREE.AmbientLight(0xffffff, 0.8);
scene.add(ambLight);

const frontLight = new THREE.PointLight(0xffffff, 0.8);
frontLight.position.set(0, 0.5, 2);
scene.add(frontLight);

/* --------------------------------------------------
   MODEL LADEN  (mit Blendshape-Erkennung)
-------------------------------------------------- */
const loader = new THREE.GLTFLoader();
loader.load("./avatar.glb", gltf => {

  model = gltf.scene;

  // === Gr√∂√üe & Position ‚Äì bleibt wie bisher ===
  const box = new THREE.Box3().setFromObject(model);
  const size = box.getSize(new THREE.Vector3());
  model.scale.setScalar((1.5 / Math.max(size.x, size.y, size.z)) * 0.8);

  const center = box.getCenter(new THREE.Vector3());
  model.position.sub(center);

  baseY = model.position.y;
  model.rotation.y = baseRotY - Math.PI / 2;
  model.rotation.x = baseRotX;

  /* --------------------------------------------------
     üîé Blendshapes AUTOMATISCH FINDEN (saubere Variante)
  -------------------------------------------------- */
  model.traverse(obj => {
    if (obj.isMesh && obj.morphTargetDictionary) {
      console.log("Mesh:", obj.name, obj.morphTargetDictionary);

      for (const [name, idx] of Object.entries(obj.morphTargetDictionary)) {
        const lower = name.toLowerCase();

      if (lower.includes("jaw"))        jawOpenIndex = idx;
      if (lower.includes("wide"))       mouthWideIndex = idx;
      if (lower.includes("puck"))       mouthPuckerIndex = idx;
      if (lower.includes("smile"))      mouthSmileIndex = idx;
      if (lower.includes("frown"))      mouthFrownIndex = idx;

      }
    }
  });

  console.log("‚úî FINAL Blendshape-Indices:",
              "jawOpen =", jawOpenIndex,
              "| mouthWide =", mouthWideIndex,
              "| mouthPucker =", mouthPuckerIndex);

  // === MODEL STARTEN ===
  scene.add(model);
  document.getElementById("loading").style.display = "none";
  animate();
});
  /* --------------------------------------------------
   BLENDSHAPE SETZEN ‚Äì GLOBAL & VOR SPEAK EINBINDEN!
-------------------------------------------------- */
function setBlendshape(index, value) {
  if (index === null || !model) return;

  model.traverse(obj => {
    if (obj.isMesh && obj.morphTargetInfluences) {
      obj.morphTargetInfluences[index] = value;
    }
  });
}

// ====================================
// ANIMATE ‚Äì FINAL & STABIL
// ====================================
function animate() {
  requestAnimationFrame(animate);
  if (!model) return;

  const now = performance.now();
  const frontalY = -Math.PI / 2;               // frontal
  const rightY   = baseRotY - Math.PI / 2;     // Startpose rechts
  const leftY    = frontalY + 0.25;            // Hmmm = leicht links

  // üßä Idle-Mundhaltung nur, wenn NICHT gesprochen wird
  //    und kein Cooldown / Nachzittern aktiv ist:
  if (!talking && !justFinishedSpeaking && !mouthCooldown) {
    setBlendshape(jawOpenIndex, 0.05);  // dezente Atmung
    setBlendshape(mouthWideIndex, 0.0);
    setBlendshape(mouthPuckerIndex, 0.0);
  }

  // 0Ô∏è‚É£ START: Ausgangsposition (leicht rechts)
  if (frontalFix) {
    model.rotation.y = THREE.MathUtils.lerp(model.rotation.y, rightY, 0.08);
    model.rotation.x = THREE.MathUtils.lerp(model.rotation.x, baseRotX, 0.08);
    renderer.render(scene, camera);
    return;
  }

  // 1Ô∏è‚É£ GREET / ANTWORTBEGINN ‚Üí FRONTAL
  if (rising) {
    const t = (now - riseStartTime) / riseDuration;
    model.rotation.y = THREE.MathUtils.lerp(model.rotation.y, frontalY, 0.06);
    model.rotation.x = THREE.MathUtils.lerp(model.rotation.x, 0, 0.06);
    if (t >= 1) rising = false;
  }

  // 2Ô∏è‚É£ HMMM ‚Üí LANGSAM LINKS
  else if (hmNeigen) {
    const t = Math.min(1, (now - hmStartTime) / hmDuration);
    model.rotation.x = THREE.MathUtils.lerp(model.rotation.x, baseRotX + 0.25, t);
    model.rotation.y = THREE.MathUtils.lerp(model.rotation.y, leftY, t);
  }

  // 3Ô∏è‚É£ ANTWORT ‚Üí FRONTAL
  else if (STATE === "answer") {
    model.position.y = baseY + Math.sin(now * 0.0015) * 0.008;
    model.rotation.y = THREE.MathUtils.lerp(model.rotation.y, frontalY, 0.03);
    model.rotation.x = THREE.MathUtils.lerp(model.rotation.x, 0, 0.03);
  }

  // 4Ô∏è‚É£ TALKING = SPRICHT ‚Üí FRONTAL & ATMEN
  else if (talking) {
    model.position.y = baseY + Math.sin(now * 0.0015) * 0.008;
    model.rotation.y = THREE.MathUtils.lerp(model.rotation.y, frontalY, 0.03);
    model.rotation.x = THREE.MathUtils.lerp(model.rotation.x, 0, 0.03);
  }

  // 5Ô∏è‚É£ WARTET AUF FRAGE ‚Üí FRONTAL
  else if (STATE === "listen" || STATE === "greet") {
    model.position.y = baseY + Math.sin(now * 0.0012) * 0.006;
    model.rotation.y = THREE.MathUtils.lerp(model.rotation.y, frontalY, 0.03);
    model.rotation.x = THREE.MathUtils.lerp(model.rotation.x, 0, 0.03);
  }

  // 6Ô∏è‚É£ ENDE ‚Üí SANFT ZUR√úCK NACH RECHTS
  else if (STATE === "idle" && !talking && !rising) {
    const breathSpeed = 0.0011 + Math.sin(now * 0.00005) * 0.0004;
    const breathAmp   = 0.006  + Math.sin(now * 0.00008) * 0.003;
    model.position.y  = baseY + Math.sin(now * breathSpeed) * breathAmp;

    model.rotation.y = THREE.MathUtils.lerp(model.rotation.y, rightY, 0.03);
    model.rotation.x = THREE.MathUtils.lerp(model.rotation.x, baseRotX, 0.03);
  }

  // ‚≠ê Sehr dezente, w√ºrdige Kopf-Driftbewegungen (Kaiser-Version 3.0)
const driftX = Math.sin(now * 0.0004) * 0.015;   // langsames, kaum sichtbares Nicken
const driftY = Math.sin(now * 0.0003) * 0.012;   // sehr sanfte Seitbewegung

// X-Achse ‚Üí sanft um baseRotX
model.rotation.x = THREE.MathUtils.lerp(
  model.rotation.x,
  baseRotX + driftX,
  0.02
);

// Y-Achse ‚Üí um fixe Basis (keine Aufschaukelung)
if (!hmNeigen && !rising) {
  const baseYawForDrift = (STATE === "idle") ? rightY : frontalY;
  const targetYaw = baseYawForDrift + driftY;

  model.rotation.y = THREE.MathUtils.lerp(
    model.rotation.y,
    targetYaw,
    0.02
  );
}
  renderer.render(scene, camera);
}

/* -----------------------------
   STATE MACHINE ‚Äì LOGIK (FINAL)
----------------------------- */

let recognition;
if ("webkitSpeechRecognition" in window) {
  recognition = new webkitSpeechRecognition();
  recognition.lang = "de-DE";
  recognition.continuous = false;

  recognition.onresult = e => {
    lastTranscript = e.results[0][0].transcript;
  };

  recognition.onend = () => {

    // üõ°Ô∏è Wake-Stabilizer: Ghost-onend direkt nach Sleep ignorieren
    if (wakeStabilizing) {
      console.warn("‚è∏Ô∏è recognition.onend ignoriert (Wake-Stabilizer)");
      recRunning = false;
      return;
    }

    // üõ°Ô∏è Ghost-onend ohne aktiven Start ignorieren
    if (!recRunning) {
      console.warn("‚è∏Ô∏è recognition.onend ohne recRunning ‚Äì ignoriert");
      return;
    }

    // üõ°Ô∏è Doppeltes onend verhindern
    if (recognitionHandled) {
      console.warn("üõë recognition.onend doppelt ‚Äì ignoriert");
      return;
    }
    recognitionHandled = true;

    recRunning = false;

    if (STATE === "listen" && lastTranscript) {

      // üõ°Ô∏è nur eine /ask pro Durchlauf
      if (askInProgress) return;
      askInProgress = true;

      // 1Ô∏è‚É£ HMMM
      resetMovements();
      STATE = "hmmm";
      hmNeigen = true;
      hmStartTime = performance.now();
      speak("√Ñhm..... einen Moment", true);

      setTimeout(() => {

        fetch("/ask", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ text: lastTranscript })
        })
        .then(r => r.json())
        .then(data => {

          resetMovements();
          STATE = "answer";
          rising = true;
          riseStartTime = performance.now();

          fetch("/tts", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ text: data.answer })
          })
          .then(r => r.json())
          .then(dataTTS => {
            playAudioAndLipsync(dataTTS.audio, dataTTS.lipsync);
          })
          .catch(() => {
            speak(data.answer);
          });

          const waitUntilDone = setInterval(() => {
            if (!talking && !rising) {
              clearInterval(waitUntilDone);
              resetMovements();
              greeted = false;
              STATE = "idle";
              askInProgress = false;
              toIdlePose = true;
              toIdleStart = performance.now();
            }
          }, 200);

        })
        .catch(() => {
          askInProgress = false;
          resetMovements();
          STATE = "idle";
        });

      }, 4000);

    } else {
      resetMovements();
      STATE = "idle";
    }
  };
}

/* ===============================
   üèõÔ∏è MUSEUMS-RESET (Wake / Fokus)
================================ */

function museumReset(reason = "") {
  console.log("üõ°Ô∏è Museum-Reset", reason);

  // üõ°Ô∏è Wake-Guard: erster Klick nach Sleep wird ignoriert
  wakeGuard = true;
  setTimeout(() => {
    wakeGuard = false;
    console.log("üü¢ Wake-Guard aufgehoben");
  }, 600);

  // üõ°Ô∏è Wake-Stabilisierung: Recognition nach Sleep blocken
  wakeStabilizing = true;
  setTimeout(() => {
    wakeStabilizing = false;
    console.log("üü¢ Wake stabilisiert");
  }, 1200);

  // --- Speech sauber abbrechen ---
  try {
    speechSynthesis.cancel();
  } catch (e) {}

  if (typeof recognition !== "undefined" && recognition && recRunning) {
    try {
      recognition.abort();
    } catch (e) {}
    recRunning = false;
  }

  // --- State Machine auf Urzustand ---
  STATE = "idle";
  greeted = false;
  talking = false;
  rising = false;
  hmNeigen = false;
  frontalFix = false;

  lastTranscript = "";
  justFinishedSpeaking = false;
  mouthCooldown = false;

  // Guards zur√ºcksetzen
  recognitionHandled = false;
  askInProgress = false;

  // --- Mund neutralisieren ---
  if (jawOpenIndex !== null) {
    setBlendshape(jawOpenIndex, 0);
    setBlendshape(mouthWideIndex, 0);
    setBlendshape(mouthPuckerIndex, 0);
    setBlendshape(mouthSmileIndex, 0);
    setBlendshape(mouthFrownIndex, 0);
  }

  // --- Kopf & Position neutral ---
  if (model) {
    model.position.y = baseY;
    model.rotation.x = baseRotX;
    model.rotation.y = baseRotY - Math.PI / 2;
  }
}

// üîÅ Trigger nur im echten Idle
document.addEventListener("visibilitychange", () => {
  if (!document.hidden && STATE === "idle" && !talking && !recRunning) {
    museumReset("visibilitychange");
  }
});

window.addEventListener("focus", () => {
  if (STATE === "idle" && !talking && !recRunning) {
    museumReset("focus");
  }
});


/* -----------------------------
   BUTTON ‚Äì GREET & LISTEN
----------------------------- */
document.getElementById("micBtn").onclick = () => {

  // üõ°Ô∏è Wake-Guard: erster Klick nach Ruhemodus tut nichts
  if (wakeGuard) {
    console.log("‚è≥ Klick ignoriert (Wake-Guard)");
    return;
  }

  // Erste Bet√§tigung ‚Üí Begr√º√üung
  if (!greeted) {
    resetMovements();
    greeted = true;
    STATE = "greet";

    frontalFix = false;
    rising = true;
    riseStartTime = performance.now();

    speak(
      "Seid gegr√º√üt, mein Freund. Ich bin Friedrich Barbarossa, nach fast neunhundert Jahren im Kaiserberg zu Lautern erwacht. Was ist Euer Begehr.",
      false
    );
    return;
  }

  // Spracherkennung vorhanden?
  if (!recognition) {
    alert("Spracherkennung wird nicht unterst√ºtzt.");
    return;
  }

  if (recRunning) {
    console.warn("‚ùóRECOGNITION BLOCKED ‚Äî already running");
    return;
  }

  // üõ°Ô∏è Guards f√ºr neuen Durchlauf zur√ºcksetzen
  recognitionHandled = false;
  askInProgress = false;

  resetMovements();
  lastTranscript = "";
  STATE = "listen";

  try {
    recognition.start();
    recRunning = true;
  } catch (e) {
    console.warn("‚ùóRecognition start error:", e);
    recRunning = false;
  }
};

/* -----------------------------
   1) M√ÑNNLICHE STIMME FEST SETZEN  (GLOBAL!)
----------------------------- */
let maleVoice = null;

function setMaleVoice() {
  const voices = speechSynthesis.getVoices();

  if (!voices.length) {
    setTimeout(setMaleVoice, 150);
    return;
  }

  maleVoice = voices.find(v => v.name === "Microsoft Stefan - German (Germany)");
  console.log("Ausgew√§hlte Stimme:", maleVoice);
}

speechSynthesis.onvoiceschanged = setMaleVoice;
setMaleVoice();

/* --------------------------------
   WICHTIG: Diese Funktion muss
   VOR speak() im Code stehen:
----------------------------------- */
function setBlendshape(index, value) {
  if (!model) return;
  model.traverse(obj => {
    if (obj.isMesh && obj.morphTargetInfluences && index !== null) {
      obj.morphTargetInfluences[index] = value;
    }
  });
}
function lerp(a, b, t) {  // linearer √úbergang
  return a + (b - a) * t;
}

function getBlendshape(index) {
  let value = 0;
  model.traverse(obj => {
    if (obj.isMesh && obj.morphTargetInfluences) {
      value = obj.morphTargetInfluences[index] ?? 0;
    }
  });
  return value;
}
/* -----------------------------
   SPEAK ‚Äì NAT√úRLICH & STABIL
----------------------------- */
function speak(text, slow = false) {
  const u = new SpeechSynthesisUtterance(text);
  u.lang = "de-DE";
  u.rate = slow ? 0.75 : 1.1;

  // Verwende m√§nnliche Stimme, wenn verf√ºgbar
  if (maleVoice) {
    u.voice = maleVoice;
  }

  let lipsyncInterval = null;
  let t = 0;

  /* -----------------------------
     START DES SPRECHENS
  ----------------------------- */
  u.onstart = () => {
    talking = true;
    mouthCooldown = false;
    justFinishedSpeaking = false;

    lipsyncInterval = setInterval(() => {
      t += slow ? 0.05 : 0.1;

      // ‚≠ê Barbarossa Lipsync ‚Äì KAISER 2.2
      // nat√ºrlich, ruhig, artikuliert

      // 1) Basisfrequenzen
      let jaw =
        Math.abs(Math.sin(t * 1.2)) * 0.26 +
        Math.abs(Math.sin(t * 0.58)) * 0.18 +
        Math.abs(Math.sin(t * 2.0)) * 0.08;

      // 2) leichte Variation
      jaw += (Math.random() * 0.06 - 0.03);

      // 3) kleine Schlie√üimpulse (deutlichere Artikulation)
      if (t % 0.18 < 0.02) {
        jaw *= 0.12;   // st√§rker & etwas h√§ufiger schlie√üen
      }

      // 4) Konsonantenimpulse (dezent)
      if (Math.random() < 0.03) jaw *= 1.25;

      // 5) Begrenzen
      jaw = Math.min(Math.max(jaw, 0), 0.50);

      // 6) Gl√§ttung (realistisch, nicht zitterig)
      jaw = lerp(getBlendshape(jawOpenIndex), jaw, 0.20);

      // ====== Sekund√§rformen ======
      const wide  = jaw * (0.45 + Math.random() * 0.25); // breiter als vorher
      const puck  = jaw * (0.15 + Math.random() * 0.12);

      // ====== Ausdruck ======
      const smile = jaw * (0.05 + Math.random() * 0.10); // ruhiger
      const frown = jaw * (0.04 + Math.random() * 0.10);

      // ‚≠ê NEU: Oberlippen-Aktivierung (sehr subtil)
      const upperLipBoost = jaw * 0.18;

      // ====== SETZEN ======
      setBlendshape(jawOpenIndex, jaw);
      setBlendshape(mouthWideIndex, wide);
      setBlendshape(mouthPuckerIndex, puck);
      setBlendshape(mouthSmileIndex, smile + upperLipBoost);
      setBlendshape(mouthFrownIndex, frown * 0.9);

    }, 38);
  };

  /* -----------------------------
     ENDE DES SPRECHENS
  ----------------------------- */
  u.onend = () => {
    clearInterval(lipsyncInterval);
    lipsyncInterval = null;
    talking = false;

    // ‚≠ê Satzende ‚Üí Mund entspannen (nur bei echter Antwort)
if (STATE === "answer" && /[.!?]\s*$/.test(text.trim())) {
  setBlendshape(jawOpenIndex, 0);
  setBlendshape(mouthWideIndex, 0);
  setBlendshape(mouthPuckerIndex, 0);
  setBlendshape(mouthSmileIndex, 0);
  setBlendshape(mouthFrownIndex, 0);
}

    // ‚≠ê Cooldown gegen Nachklappern
    justFinishedSpeaking = true;
    mouthCooldown = true;

    setTimeout(() => {
      justFinishedSpeaking = false;
      mouthCooldown = false;
    }, 20);
  };

  // Start TTS
  speechSynthesis.speak(u);
}
/* -----------------------------
   RESIZE
----------------------------- */
window.addEventListener("resize", () => {
  camera.aspect = window.innerWidth / window.innerHeight;
  camera.updateProjectionMatrix();
  renderer.setSize(window.innerWidth, window.innerHeight);
});
</script>
</body>
</html>
